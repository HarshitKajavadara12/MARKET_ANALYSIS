{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Indian Stock Market Correlation Study\\n\",\n",
    "    \"## Market Research System v1.0 - Exploratory Data Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Created:** January 2022  \\n\",\n",
    "    \"**Last Updated:** December 2022  \\n\",\n",
    "    \"**Focus:** Indian Stock Market (NSE/BSE)  \\n\",\n",
    "    \"**Objective:** Analyze correlations between major Indian stocks, sectors, and economic indicators\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìä Setup and Dependencies\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Install required packages in Google Colab\\n\",\n",
    "    \"!pip install yfinance pandas numpy matplotlib seaborn plotly scipy\\n\",\n",
    "    \"!pip install nsepy  # For Indian stock data\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import yfinance as yf\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import plotly.graph_objects as go\\n\",\n",
    "    \"import plotly.express as px\\n\",\n",
    "    \"from plotly.subplots import make_subplots\\n\",\n",
    "    \"from scipy import stats\\n\",\n",
    "    \"from datetime import datetime, timedelta\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set display options\\n\",\n",
    "    \"pd.set_option('display.max_columns', None)\\n\",\n",
    "    \"pd.set_option('display.max_rows', 100)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plotting style\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ All dependencies loaded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"üìÖ Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üè¢ Indian Stock Universe Definition (2022 Focus)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define Indian stock universe (NSE symbols with .NS suffix for Yahoo Finance)\\n\",\n",
    "    \"NIFTY_50_STOCKS = {\\n\",\n",
    "    \"    # Technology Sector\\n\",\n",
    "    \"    'TCS.NS': 'Tata Consultancy Services',\\n\",\n",
    "    \"    'INFY.NS': 'Infosys',\\n\",\n",
    "    \"    'HCLTECH.NS': 'HCL Technologies',\\n\",\n",
    "    \"    'WIPRO.NS': 'Wipro',\\n\",\n",
    "    \"    'TECHM.NS': 'Tech Mahindra',\\n\",\n",
    "    \"    'LTI.NS': 'L&T Infotech',\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Banking & Financial Services\\n\",\n",
    "    \"    'HDFCBANK.NS': 'HDFC Bank',\\n\",\n",
    "    \"    'ICICIBANK.NS': 'ICICI Bank',\\n\",\n",
    "    \"    'SBIN.NS': 'State Bank of India',\\n\",\n",
    "    \"    'AXISBANK.NS': 'Axis Bank',\\n\",\n",
    "    \"    'KOTAKBANK.NS': 'Kotak Mahindra Bank',\\n\",\n",
    "    \"    'INDUSINDBK.NS': 'IndusInd Bank',\\n\",\n",
    "    \"    'BAJFINANCE.NS': 'Bajaj Finance',\\n\",\n",
    "    \"    'HDFCLIFE.NS': 'HDFC Life Insurance',\\n\",\n",
    "    \"    'SBILIFE.NS': 'SBI Life Insurance',\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Energy & Oil\\n\",\n",
    "    \"    'RELIANCE.NS': 'Reliance Industries',\\n\",\n",
    "    \"    'ONGC.NS': 'Oil & Natural Gas Corp',\\n\",\n",
    "    \"    'BPCL.NS': 'Bharat Petroleum',\\n\",\n",
    "    \"    'IOC.NS': 'Indian Oil Corporation',\\n\",\n",
    "    \"    'GAIL.NS': 'GAIL India',\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Automobiles\\n\",\n",
    "    \"    'MARUTI.NS': 'Maruti Suzuki',\\n\",\n",
    "    \"    'M&M.NS': 'Mahindra & Mahindra',\\n\",\n",
    "    \"    'TATAMOTORS.NS': 'Tata Motors',\\n\",\n",
    "    \"    'BAJAJ-AUTO.NS': 'Bajaj Auto',\\n\",\n",
    "    \"    'HEROMOTOCO.NS': 'Hero MotoCorp',\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # FMCG\\n\",\n",
    "    \"    'HINDUNILVR.NS': 'Hindustan Unilever',\\n\",\n",
    "    \"    'ITC.NS': 'ITC Limited',\\n\",\n",
    "    \"    'NESTLEIND.NS': 'Nestle India',\\n\",\n",
    "    \"    'BRITANNIA.NS': 'Britannia Industries',\\n\",\n",
    "    \"    'DABUR.NS': 'Dabur India',\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Pharmaceuticals\\n\",\n",
    "    \"    'SUNPHARMA.NS': 'Sun Pharmaceutical',\\n\",\n",
    "    \"    'DRREDDY.NS': 'Dr. Reddys Laboratories',\\n\",\n",
    "    \"    'CIPLA.NS': 'Cipla',\\n\",\n",
    "    \"    'DIVISLAB.NS': 'Divis Laboratories',\\n\",\n",
    "    \"    'BIOCON.NS': 'Biocon',\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Metals & Mining\\n\",\n",
    "    \"    'TATASTEEL.NS': 'Tata Steel',\\n\",\n",
    "    \"    'HINDALCO.NS': 'Hindalco Industries',\\n\",\n",
    "    \"    'JSW.NS': 'JSW Steel',\\n\",\n",
    "    \"    'COALINDIA.NS': 'Coal India',\\n\",\n",
    "    \"    'VEDL.NS': 'Vedanta Limited',\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Infrastructure & Construction\\n\",\n",
    "    \"    'LT.NS': 'Larsen & Toubro',\\n\",\n",
    "    \"    'ULTRACEMCO.NS': 'UltraTech Cement',\\n\",\n",
    "    \"    'GRASIM.NS': 'Grasim Industries',\\n\",\n",
    "    \"    'ADANIPORTS.NS': 'Adani Ports',\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Telecom\\n\",\n",
    "    \"    'BHARTIARTL.NS': 'Bharti Airtel',\\n\",\n",
    "    \"    'JIO.NS': 'Reliance Jio' # Note: May not be available in 2022\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Market Indices\\n\",\n",
    "    \"INDIAN_INDICES = {\\n\",\n",
    "    \"    '^NSEI': 'NIFTY 50',\\n\",\n",
    "    \"    '^BSESN': 'BSE SENSEX',\\n\",\n",
    "    \"    '^NSEBANK': 'NIFTY Bank',\\n\",\n",
    "    \"    '^NSEIT': 'NIFTY IT',\\n\",\n",
    "    \"    'NIFTYFMCG.NS': 'NIFTY FMCG',\\n\",\n",
    "    \"    'CNXAUTO.NS': 'NIFTY Auto'\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sector Classification\\n\",\n",
    "    \"SECTORS = {\\n\",\n",
    "    \"    'Technology': ['TCS.NS', 'INFY.NS', 'HCLTECH.NS', 'WIPRO.NS', 'TECHM.NS', 'LTI.NS'],\\n\",\n",
    "    \"    'Banking': ['HDFCBANK.NS', 'ICICIBANK.NS', 'SBIN.NS', 'AXISBANK.NS', 'KOTAKBANK.NS', 'INDUSINDBK.NS'],\\n\",\n",
    "    \"    'Energy': ['RELIANCE.NS', 'ONGC.NS', 'BPCL.NS', 'IOC.NS', 'GAIL.NS'],\\n\",\n",
    "    \"    'Automobiles': ['MARUTI.NS', 'M&M.NS', 'TATAMOTORS.NS', 'BAJAJ-AUTO.NS', 'HEROMOTOCO.NS'],\\n\",\n",
    "    \"    'FMCG': ['HINDUNILVR.NS', 'ITC.NS', 'NESTLEIND.NS', 'BRITANNIA.NS', 'DABUR.NS'],\\n\",\n",
    "    \"    'Pharmaceuticals': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS', 'BIOCON.NS'],\\n\",\n",
    "    \"    'Metals': ['TATASTEEL.NS', 'HINDALCO.NS', 'JSW.NS', 'COALINDIA.NS', 'VEDL.NS'],\\n\",\n",
    "    \"    'Infrastructure': ['LT.NS', 'ULTRACEMCO.NS', 'GRASIM.NS', 'ADANIPORTS.NS']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üìà Total stocks to analyze: {len(NIFTY_50_STOCKS)}\\\")\\n\",\n",
    "    \"print(f\\\"üè≠ Sectors defined: {len(SECTORS)}\\\")\\n\",\n",
    "    \"print(f\\\"üìä Indices to track: {len(INDIAN_INDICES)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìÖ Data Collection Period Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define analysis period (2022 focus)\\n\",\n",
    "    \"START_DATE = '2020-01-01'  # Historical context\\n\",\n",
    "    \"END_DATE = '2022-12-31'    # 2022 end\\n\",\n",
    "    \"\\n\",\n",
    "    \"# For correlation analysis - different time windows\\n\",\n",
    "    \"CORRELATION_PERIODS = {\\n\",\n",
    "    \"    'Full Period': (START_DATE, END_DATE),\\n\",\n",
    "    \"    '2022 Only': ('2022-01-01', '2022-12-31'),\\n\",\n",
    "    \"    'COVID Recovery': ('2021-01-01', '2022-12-31'),\\n\",\n",
    "    \"    'Last 6 Months': ('2022-07-01', '2022-12-31'),\\n\",\n",
    "    \"    'Last 3 Months': ('2022-10-01', '2022-12-31')\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üìä Analysis Period: {START_DATE} to {END_DATE}\\\")\\n\",\n",
    "    \"print(f\\\"üîç Correlation windows: {list(CORRELATION_PERIODS.keys())}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üíæ Data Fetching Functions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def fetch_stock_data(symbols, start_date, end_date, column='Adj Close'):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Fetch stock data for multiple symbols from Yahoo Finance\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    data = pd.DataFrame()\\n\",\n",
    "    \"    failed_symbols = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"üì• Fetching data for {len(symbols)} symbols...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, symbol in enumerate(symbols):\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            stock = yf.Ticker(symbol)\\n\",\n",
    "    \"            hist = stock.history(start=start_date, end=end_date)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if not hist.empty and len(hist) > 50:  # Minimum data points\\n\",\n",
    "    \"                data[symbol] = hist[column]\\n\",\n",
    "    \"                print(f\\\"‚úÖ {symbol}: {len(hist)} data points\\\")\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                failed_symbols.append(symbol)\\n\",\n",
    "    \"                print(f\\\"‚ùå {symbol}: Insufficient data\\\")\\n\",\n",
    "    \"                \\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            failed_symbols.append(symbol)\\n\",\n",
    "    \"            print(f\\\"‚ùå {symbol}: Error - {str(e)}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nüìä Successfully fetched: {len(data.columns)} stocks\\\")\\n\",\n",
    "    \"    print(f\\\"‚ùå Failed: {len(failed_symbols)} stocks\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if failed_symbols:\\n\",\n",
    "    \"        print(f\\\"Failed symbols: {failed_symbols}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return data.dropna()\\n\",\n",
    "    \"\\n\",\n",
    "    \"def calculate_returns(price_data, method='daily'):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Calculate returns from price data\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    if method == 'daily':\\n\",\n",
    "    \"        returns = price_data.pct_change().dropna()\\n\",\n",
    "    \"    elif method == 'weekly':\\n\",\n",
    "    \"        weekly_prices = price_data.resample('W').last()\\n\",\n",
    "    \"        returns = weekly_prices.pct_change().dropna()\\n\",\n",
    "    \"    elif method == 'monthly':\\n\",\n",
    "    \"        monthly_prices = price_data.resample('M').last()\\n\",\n",
    "    \"        returns = monthly_prices.pct_change().dropna()\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        raise ValueError(\\\"Method must be 'daily', 'weekly', or 'monthly'\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return returns\\n\",\n",
    "    \"\\n\",\n",
    "    \"def clean_symbol_names(data, symbol_mapping):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Clean symbol names for better visualization\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    clean_data = data.copy()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Rename columns to company names\\n\",\n",
    "    \"    rename_dict = {}\\n\",\n",
    "    \"    for symbol in clean_data.columns:\\n\",\n",
    "    \"        if symbol in symbol_mapping:\\n\",\n",
    "    \"            company_name = symbol_mapping[symbol]\\n\",\n",
    "    \"            # Shorten long names\\n\",\n",
    "    \"            if len(company_name) > 15:\\n\",\n",
    "    \"                company_name = company_name.split()[0]  # Take first word\\n\",\n",
    "    \"            rename_dict[symbol] = company_name\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            rename_dict[symbol] = symbol.replace('.NS', '')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    clean_data.rename(columns=rename_dict, inplace=True)\\n\",\n",
    "    \"    return clean_data\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üîß Data fetching functions defined successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìä Main Data Collection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Fetch stock price data\\n\",\n",
    "    \"print(\\\"üöÄ Starting data collection...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get all stock symbols\\n\",\n",
    "    \"all_symbols = list(NIFTY_50_STOCKS.keys())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Remove potentially unavailable symbols for 2022\\n\",\n",
    "    \"available_symbols = [s for s in all_symbols if s != 'JIOL.NS']  # Jio might not be listed in 2022\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fetch price data\\n\",\n",
    "    \"price_data = fetch_stock_data(available_symbols, START_DATE, END_DATE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìà Price data shape: {price_data.shape}\\\")\\n\",\n",
    "    \"print(f\\\"üìÖ Date range: {price_data.index[0].date()} to {price_data.index[-1].date()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate daily returns\\n\",\n",
    "    \"daily_returns = calculate_returns(price_data, 'daily')\\n\",\n",
    "    \"print(f\\\"üìä Daily returns shape: {daily_returns.shape}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate weekly and monthly returns for different correlation studies\\n\",\n",
    "    \"weekly_returns = calculate_returns(price_data, 'weekly')\\n\",\n",
    "    \"monthly_returns = calculate_returns(price_data, 'monthly')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üìä Weekly returns shape: {weekly_returns.shape}\\\")\\n\",\n",
    "    \"print(f\\\"üìä Monthly returns shape: {monthly_returns.shape}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display first few rows\\n\",\n",
    "    \"print(\\\"\\\\nüìã Sample of daily returns data:\\\")\\n\",\n",
    "    \"print(daily_returns.head())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîç Basic Data Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Basic statistics\\n\",\n",
    "    \"print(\\\"üìà BASIC STATISTICS FOR INDIAN STOCKS (2020-2022)\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Daily returns statistics\\n\",\n",
    "    \"returns_stats = daily_returns.describe()\\n\",\n",
    "    \"print(\\\"\\\\nüìä Daily Returns Statistics:\\\")\\n\",\n",
    "    \"print(returns_stats.round(4))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Annualized statistics\\n\",\n",
    "    \"annual_returns = daily_returns.mean() * 252\\n\",\n",
    "    \"annual_volatility = daily_returns.std() * np.sqrt(252)\\n\",\n",
    "    \"sharpe_ratio = annual_returns / annual_volatility\\n\",\n",
    "    \"\\n\",\n",
    "    \"performance_summary = pd.DataFrame({\\n\",\n",
    "    \"    'Annual Return': annual_returns,\\n\",\n",
    "    \"    'Annual Volatility': annual_volatility,\\n\",\n",
    "    \"    'Sharpe Ratio': sharpe_ratio\\n\",\n",
    "    \"}).round(4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüìä Annualized Performance Metrics:\\\")\\n\",\n",
    "    \"print(performance_summary.sort_values('Sharpe Ratio', ascending=False))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Best and worst performers\\n\",\n",
    "    \"print(\\\"\\\\nüèÜ TOP PERFORMERS (by Sharpe Ratio):\\\")\\n\",\n",
    "    \"top_performers = performance_summary.sort_values('Sharpe Ratio', ascending=False).head(10)\\n\",\n",
    "    \"for i, (stock, metrics) in enumerate(top_performers.iterrows(), 1):\\n\",\n",
    "    \"    print(f\\\"{i:2d}. {stock:<15} - Sharpe: {metrics['Sharpe Ratio']:6.3f}, Return: {metrics['Annual Return']*100:6.2f}%\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüìâ WORST PERFORMERS (by Sharpe Ratio):\\\")\\n\",\n",
    "    \"worst_performers = performance_summary.sort_values('Sharpe Ratio', ascending=True).head(5)\\n\",\n",
    "    \"for i, (stock, metrics) in enumerate(worst_performers.iterrows(), 1):\\n\",\n",
    "    \"    print(f\\\"{i:2d}. {stock:<15} - Sharpe: {metrics['Sharpe Ratio']:6.3f}, Return: {metrics['Annual Return']*100:6.2f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîó Correlation Analysis Functions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def calculate_correlation_matrix(returns_data, method='pearson'):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Calculate correlation matrix with statistical significance\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    correlation_matrix = returns_data.corr(method=method)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate p-values for correlations\\n\",\n",
    "    \"    n = len(returns_data)\\n\",\n",
    "    \"    pvalue_matrix = pd.DataFrame(index=correlation_matrix.index, \\n\",\n",
    "    \"                                columns=correlation_matrix.columns)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in correlation_matrix.index:\\n\",\n",
    "    \"        for j in correlation_matrix.columns:\\n\",\n",
    "    \"            if i != j:\\n\",\n",
    "    \"                corr_coef = correlation_matrix.loc[i, j]\\n\",\n",
    "    \"                # Calculate t-statistic and p-value\\n\",\n",
    "    \"                t_stat = corr_coef * np.sqrt((n-2)/(1-corr_coef**2))\\n\",\n",
    "    \"                p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n-2))\\n\",\n",
    "    \"                pvalue_matrix.loc[i, j] = p_value\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                pvalue_matrix.loc[i, j] = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return correlation_matrix, pvalue_matrix.astype(float)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def find_highly_correlated_pairs(correlation_matrix, threshold=0.7):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Find pairs of stocks with high correlation\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    high_corr_pairs = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in range(len(correlation_matrix.columns)):\\n\",\n",
    "    \"        for j in range(i+1, len(correlation_matrix.columns)):\\n\",\n",
    "    \"            stock1 = correlation_matrix.columns[i]\\n\",\n",
    "    \"            stock2 = correlation_matrix.columns[j]\\n\",\n",
    "    \"            corr_value = correlation_matrix.iloc[i, j]\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if abs(corr_value) >= threshold:\\n\",\n",
    "    \"                high_corr_pairs.append({\\n\",\n",
    "    \"                    'Stock 1': stock1,\\n\",\n",
    "    \"                    'Stock 2': stock2,\\n\",\n",
    "    \"                    'Correlation': corr_value,\\n\",\n",
    "    \"                    'Abs Correlation': abs(corr_value)\\n\",\n",
    "    \"                })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return pd.DataFrame(high_corr_pairs).sort_values('Abs Correlation', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def sector_correlation_analysis(returns_data, sectors_dict):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Analyze correlation within and across sectors\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    sector_correlations = {}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for sector_name, stocks in sectors_dict.items():\\n\",\n",
    "    \"        # Filter stocks that exist in our data\\n\",\n",
    "    \"        available_stocks = [s for s in stocks if s in returns_data.columns]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if len(available_stocks) >= 2:\\n\",\n",
    "    \"            sector_data = returns_data[available_stocks]\\n\",\n",
    "    \"            sector_corr = sector_data.corr()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Calculate average intra-sector correlation\\n\",\n",
    "    \"            corr_values = []\\n\",\n",
    "    \"            for i in range(len(sector_corr.columns)):\\n\",\n",
    "    \"                for j in range(i+1, len(sector_corr.columns)):\\n\",\n",
    "    \"                    corr_values.append(sector_corr.iloc[i, j])\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            if corr_values:\\n\",\n",
    "    \"                sector_correlations[sector_name] = {\\n\",\n",
    "    \"                    'avg_correlation': np.mean(corr_values),\\n\",\n",
    "    \"                    'max_correlation': max(corr_values),\\n\",\n",
    "    \"                    'min_correlation': min(corr_values),\\n\",\n",
    "    \"                    'std_correlation': np.std(corr_values),\\n\",\n",
    "    \"                    'stocks_count': len(available_stocks),\\n\",\n",
    "    \"                    'stocks': available_stocks\\n\",\n",
    "    \"                }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return pd.DataFrame(sector_correlations).T\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üîß Correlation analysis functions defined successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìä Overall Market Correlation Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Calculate correlation matrix for daily returns\\n\",\n",
    "    \"print(\\\"üîç OVERALL MARKET CORRELATION ANALYSIS\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"correlation_matrix, pvalue_matrix = calculate_correlation_matrix(daily_returns)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üìä Correlation matrix shape: {correlation_matrix.shape}\\\")\\n\",\n",
    "    \"print(f\\\"üìä Average correlation: {correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].mean():.4f}\\\")\\n\",\n",
    "    \"print(f\\\"üìä Median correlation: {np.median(correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)]):.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Distribution of correlations\\n\",\n",
    "    \"corr_values = correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüìà Correlation Distribution:\\\")\\n\",\n",
    "    \"print(f\\\"Min correlation: {corr_values.min():.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Max correlation: {corr_values.max():.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Standard deviation: {corr_values.std():.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Correlation ranges\\n\",\n",
    "    \"high_corr = sum(corr_values > 0.7)\\n\",\n",
    "    \"medium_corr = sum((corr_values > 0.3) & (corr_values <= 0.7))\\n\",\n",
    "    \"low_corr = sum((corr_values > 0) & (corr_values <= 0.3))\\n\",\n",
    "    \"negative_corr = sum(corr_values < 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"total_pairs = len(corr_values)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Correlation Ranges (out of {total_pairs} pairs):\\\")\\n\",\n",
    "    \"print(f\\\"High correlation (>0.7):     {high_corr:4d} ({high_corr/total_pairs*100:5.1f}%)\\\")\\n\",\n",
    "    \"print(f\\\"Medium correlation (0.3-0.7): {medium_corr:4d} ({medium_corr/total_pairs*100:5.1f}%)\\\")\\n\",\n",
    "    \"print(f\\\"Low correlation (0-0.3):      {low_corr:4d} ({low_corr/total_pairs*100:5.1f}%)\\\")\\n\",\n",
    "    \"print(f\\\"Negative correlation (<0):     {negative_corr:4d} ({negative_corr/total_pairs*100:5.1f}%)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîç High Correlation Pairs Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Find highly correlated pairs\\n\",\n",
    "    \"print(\\\"üîó HIGH CORRELATION PAIRS ANALYSIS\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Different thresholds\\n\",\n",
    "    \"thresholds = [0.8, 0.7, 0.6]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for threshold in thresholds:\\n\",\n",
    "    \"    high_corr_pairs = find_highly_correlated_pairs(correlation_matrix, threshold)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nüìä Pairs with correlation >= {threshold}:\\\")\\n\",\n",
    "    \"    print(f\\\"Total pairs found: {len(high_corr_pairs)}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if len(high_corr_pairs) > 0:\\n\",\n",
    "    \"        print(\\\"\\\\nTop 10 highly correlated pairs:\\\")\\n\",\n",
    "\n",
    "\n",
    "    not complted"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
